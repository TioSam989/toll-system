# Portuguese Toll Tariffs Scraper

A professional Python application for scraping Portuguese toll tariffs from official transportation websites.

## ğŸ—ï¸ Project Structure

```
toll-system/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ scrapers/          # Web scrapers
â”‚   â”‚   â”œâ”€â”€ base_scraper.py
â”‚   â”‚   â”œâ”€â”€ brisa_scraper.py
â”‚   â”‚   â””â”€â”€ portugal_tolls_scraper.py
â”‚   â”œâ”€â”€ parsers/           # Data parsers
â”‚   â”‚   â””â”€â”€ pdf_parser.py
â”‚   â””â”€â”€ utils/             # Utilities
â”‚       â””â”€â”€ data_exporter.py
â”œâ”€â”€ config/                # Configuration
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ data/                  # Data storage
â”‚   â”œâ”€â”€ pdfs/             # Downloaded PDFs
â”‚   â”œâ”€â”€ parsed/           # Parsed data
â”‚   â””â”€â”€ exports/          # Final exports
â”œâ”€â”€ logs/                 # Application logs
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ main.py              # Main entry point
â””â”€â”€ requirements.txt     # Dependencies
```

## ğŸš€ Features

- **Modular Architecture**: Clean separation of concerns
- **Multiple Data Sources**: Brisa Concessao, Portugal Tolls, Infraestruturas de Portugal
- **PDF Processing**: Automatic PDF download and parsing
- **Location-Based Organization**: Toll data organized by highway/location
- **Multiple Export Formats**: CSV, JSON with location grouping
- **Robust Error Handling**: Fallback mechanisms and comprehensive logging
- **Professional Logging**: Structured logging with file output

## ğŸ“¦ Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd toll-system
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Run the application**
```bash
python main.py
```

## ğŸ¯ Usage

### Basic Usage
```bash
python main.py
```

### Programmatic Usage
```python
from src.scrapers.brisa_scraper import BrisaScraper
from src.parsers.pdf_parser import PDFParser
from src.utils.data_exporter import DataExporter

# Initialize components
scraper = BrisaScraper()
parser = PDFParser()
exporter = DataExporter()

# Scrape data
data = scraper.scrape()

# Export results
exporter.export_to_json(data)
```

## ğŸ“Š Output Files

The application generates organized output in the `data/` directory:

- **`data/pdfs/`**: Downloaded PDF files
- **`data/parsed/`**: Parsed toll data organized by location
- **`data/exports/`**: Final CSV and JSON exports
- **`logs/`**: Application logs

### Location-Based JSON Structure
```json
{
  "A1 Lisboa-Porto": [
    {
      "route": "A1 Lisboa-Porto",
      "vehicle_class": "Class 1",
      "price": "22.85",
      "currency": "EUR"
    }
  ]
}
```

## ğŸ”§ Configuration

Modify `config/settings.py` to customize:
- Output directories
- Scraper timeouts
- Website URLs
- Logging configuration

## ğŸ§ª Testing

### Unit Tests
```bash
python -m pytest tests/
```

### TestCafe E2E Tests (TypeScript)
```bash
# Install dependencies
npm install

# Run all TestCafe tests
npm run test:e2e

# Run tests in headless mode
npm run test:e2e:headless

# Run tests in Firefox
npm run test:e2e:firefox

# Run specific test file
testcafe chrome tests/testcafe/initial-test.ts
```

### CLI Toll Calculator
```bash
# Calculate toll between two addresses
npm run toll-calc "Lisboa" "Porto"
npm run toll-calc "1250-161" "4000-322"
npm run toll-calc "Coimbra" "Aveiro"

# Perfect for Raspberry Pi automation
npm run toll-calc "Your Origin" "Your Destination"
```

## ğŸ“ Logging

Logs are written to:
- Console (INFO level)
- `logs/toll_scraper.log` (INFO level)

## ğŸ› ï¸ Development

### Adding New Scrapers
1. Create new scraper class inheriting from `BaseScraper`
2. Implement the `scrape()` method
3. Add to main execution flow

### Adding New Parsers
1. Create parser class in `src/parsers/`
2. Implement parsing logic
3. Integrate with data exporter

## ğŸ“‹ Requirements

- Python 3.7+
- Chrome browser (for Selenium)
- Internet connection

## ğŸ”’ Legal Notice

This scraper is intended for educational and research purposes. Ensure compliance with website terms of service and robots.txt files before use.

## ğŸ“„ License

This project is licensed under the MIT License.